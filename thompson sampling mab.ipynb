{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "## Imports and/or google colaboratory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_repo_name = 'bandits'\n",
    "github_url = 'https://github.com/matanster/' + github_repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T16:28:01.444141Z",
     "start_time": "2018-11-22T16:28:01.432838Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import random\n",
    "\n",
    "if get_ipython().__class__.__module__ == \"google.colab._shell\":\n",
    "    print('running in google colab')\n",
    "    !git clone $github_url # clone the repo so that the python files of the repo are available to the runtime\n",
    "    exec('import ' + github_repo_name + '.python_lib.bandit as bd')\n",
    "    exec('from ' + github_repo_name + '.python_lib.util import unique_argmax')\n",
    "    exec('from ' + github_repo_name + '.python_lib.plot import interval_binner, plot_series, plot_serie')\n",
    "\n",
    "\n",
    "else:\n",
    "    print('running locally')\n",
    "    \n",
    "    import python_lib.bandit as bd\n",
    "    from python_lib.util import unique_argmax\n",
    "    from python_lib.plot import interval_binner, plot_series, plot_serie\n",
    "    \n",
    "    import ipycache # consult https://github.com/rossant/ipycache#usage for usage\n",
    "    %load_ext ipycache \n",
    "    cache_file = 'cache-file' \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## a Bernoulli MAB \"solved\" with thompson sampling\n",
    "bandits (the true world) come from library code;\n",
    "solution code is in the notebook itself flexible adaptation. <br>\n",
    "inspiration credited to https://peterroelants.github.io/posts/multi-armed-bandit-implementation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:27.574344Z",
     "start_time": "2018-11-21T11:21:27.481234Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def thompson_select(beta_priors, bandits):   \n",
    "    ''' samples from the prior distribution per bandit, and selects the argmax bandit '''\n",
    "\n",
    "    beta_dist_samples = list(map(lambda k: np.random.beta(*beta_priors[k], size=1)[0], range(bandits.num_of_bandits)))\n",
    "    selection = np.argmax(beta_dist_samples)\n",
    "    \n",
    "    if selection.size == 1:\n",
    "        return selection.flat[0]\n",
    "    else:\n",
    "        return random.choice(selection) # tie break the argmax by random\n",
    "    \n",
    "    \n",
    "\n",
    "def simulate(bandits, beta_priors, n):\n",
    "    ''' unleash online learning over n turns, keeping a record of every turn'''\n",
    "    \n",
    "    beta_priors = beta_priors.copy()\n",
    "    \n",
    "    round_records = []\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        round_record = dict(priors=list(beta_priors))\n",
    "\n",
    "        k = thompson_select(beta_priors, bandits)\n",
    "        outcome = bandits.pull(k)\n",
    "\n",
    "        # the posterior computation here is a specific case to outcomes of 0 and 1. \n",
    "        # https://www.youtube.com/watch?v=hKYvZF9wXkk discusses the general case\n",
    "        if outcome == 1:\n",
    "            beta_priors[k] = (beta_priors[k][0]+1, beta_priors[k][1]) # increment the alpha param\n",
    "        elif outcome == 0:\n",
    "            beta_priors[k] = (beta_priors[k][0], beta_priors[k][1]+1) # increment the beta param\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        round_record.update(dict(k=k, outcome=outcome, posteriors=list(beta_priors)))\n",
    "\n",
    "        round_records.append(round_record)\n",
    "        \n",
    "    return pd.DataFrame.from_records(round_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:27.664048Z",
     "start_time": "2018-11-21T11:21:27.576405Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def simulate_n_times(bandits, beta_priors, turns, simulations):\n",
    "    ''' run the same simulation m times, accumulating a record of every simulation's every turn '''\n",
    "    simulation_dfs = []\n",
    "    for i in range(simulations):\n",
    "        simulation_df = simulate(bandits, beta_priors, turns)\n",
    "        simulation_dfs.append(simulation_df)\n",
    "    return simulation_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:27.724130Z",
     "start_time": "2018-11-21T11:21:27.666111Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "bandits     = bd.BanditsVec(list(map(bd.Bernoulli, [0.03, 0.3, 0.4, 0.8, 0.9, 0.95])), bd.Bernoulli.best_bandit)\n",
    "beta_priors = list(map(lambda bandit: (1,1), range(bandits.num_of_bandits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:27.791393Z",
     "start_time": "2018-11-21T11:21:27.726761Z"
    },
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "def compute_cross_simulation_stats(simulation_dfs, columns, stat_specs):\n",
    "    ''' computes turn-wise stats across simulation dataframes.\n",
    "        this is like building a data cube and aggregating the desired statistics on its new axis. '''\n",
    "    \n",
    "    # an intermediary dataframe where the index is the rounds, and each cell is the array \n",
    "    # of values across all simulations, for each original column\n",
    "    rounds_df = pd.DataFrame(index=simulation_dfs[0].index, columns=columns)\n",
    "    for column in columns:          \n",
    "        for round in range(simulation_dfs[0].shape[0]):\n",
    "            round_values = [simulation_df.iloc[round][column] for simulation_df in simulation_dfs]\n",
    "            rounds_df[column].iloc[round] = round_values\n",
    "\n",
    "    # the result dataframe where the index is the rounds, there is a column for every column+stat combo,\n",
    "    # and the values are the implied statistics\n",
    "    rounds_stats_df = pd.DataFrame(index=rounds_df.index, columns=[column + '-' + stat_spec['name'] for column in columns for stat_spec in stat_specs])\n",
    "    for round in range(simulation_dfs[0].shape[0]):\n",
    "        for column in columns:          \n",
    "            for stat_spec in stat_specs:\n",
    "                rounds_stats_df.iloc[round][column + '-' + stat_spec['name']] = \\\n",
    "                    stat_spec['fn'](rounds_df.iloc[round][column])\n",
    "        \n",
    "    return rounds_stats_df\n",
    "\n",
    "\n",
    "def get_cross_simulation_stats(simulation_dfs):\n",
    "    ''' computes the average and std per turn, for items of interest '''\n",
    "    return compute_cross_simulation_stats(simulation_dfs, ['k', 'outcome'], [dict(name='avg', fn=np.mean), dict(name='std', fn=np.std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:28.741870Z",
     "start_time": "2018-11-21T11:21:27.793851Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# %%cache $cache_file simulation_dfs, round_stats\n",
    "simulation_dfs = simulate_n_times(bandits, beta_priors, 200,1000)\n",
    "round_stats = get_cross_simulation_stats(simulation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:28.986486Z",
     "start_time": "2018-11-21T11:21:28.744766Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_series('reward per turn over {} simulations of {} rounds each'.format(simulation_dfs[0].shape[0], len(simulation_dfs)),\n",
    "            'turn', 'reward',            \n",
    "            round_stats,\n",
    "            [dict(column='outcome-avg', display_name='average'), dict(column='outcome-std', display_name='std')], \n",
    "            lines=False,\n",
    "            marker_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:29.060750Z",
     "start_time": "2018-11-21T11:21:28.988360Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_series('arm selection per turn over {} simulations of {} rounds each'.format(simulation_dfs[0].shape[0], len(simulation_dfs)),\n",
    "            'turn', 'arm',            \n",
    "            round_stats,\n",
    "            [dict(column='k-avg', display_name='average arm'), dict(column='k-std', display_name='std')], \n",
    "            lines=False,\n",
    "            marker_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T16:21:54.345106Z",
     "start_time": "2018-11-11T16:21:54.340439Z"
    }
   },
   "source": [
    "## Looking at the final posterior distributions\n",
    "more precisely the distributions of the means of the posterior of each arm. \n",
    "<br> equally put, we take the mean of the alpha and beta per arm over all simulations, and plot those beta distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:33.666326Z",
     "start_time": "2018-11-21T11:21:29.062481Z"
    }
   },
   "outputs": [],
   "source": [
    "final_alpha_posteriors = pd.DataFrame(\n",
    "    index=range(len(simulation_dfs)),\n",
    "    columns = [arm for arm in range(bandits.num_of_bandits)])\n",
    "\n",
    "final_beta_posteriors = pd.DataFrame(\n",
    "    index=range(len(simulation_dfs)),\n",
    "    columns = [arm for arm in range(bandits.num_of_bandits)])\n",
    "    \n",
    "for i, simulation_df in enumerate(simulation_dfs):\n",
    "    for arm in range(bandits.num_of_bandits):\n",
    "        final_alpha_posteriors.iloc[i][arm] = simulation_df.tail(1).iloc[0]['posteriors'][arm][0]\n",
    "        final_beta_posteriors.iloc[i][arm]  = simulation_df.tail(1).iloc[0]['posteriors'][arm][1]\n",
    "        \n",
    "mean_alpha_posteriors = final_alpha_posteriors.mean()\n",
    "mean_beta_posteriors  = final_beta_posteriors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:34.414094Z",
     "start_time": "2018-11-21T11:21:33.667964Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,1000)\n",
    "arm_estimates_df = pd.DataFrame(index=x)\n",
    "for arm in range(bandits.num_of_bandits):   \n",
    "    beta_distribution = scipy.stats.beta(mean_alpha_posteriors[arm], mean_beta_posteriors[arm])\n",
    "    arm_estimates_df[arm] = [beta_distribution.pdf(i) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:34.451701Z",
     "start_time": "2018-11-21T11:21:34.415894Z"
    }
   },
   "outputs": [],
   "source": [
    "params_df = pd.DataFrame(index = pd.Index(range(bandits.num_of_bandits), name='arm'))\n",
    "params_df['true param'] = pd.Series(map(lambda bandit: bandit.success_prob, bandits.bandits))\n",
    "params_df['mean(α)']    = pd.Series(mean_alpha_posteriors)\n",
    "params_df['mean(β)']    = pd.Series(mean_beta_posteriors)\n",
    "params_df['std(α)']     = pd.Series(final_alpha_posteriors.std())\n",
    "params_df['std(β)']     = pd.Series(final_beta_posteriors.std())\n",
    "display(params_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:21:34.723895Z",
     "start_time": "2018-11-21T11:21:34.454263Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_series('final estimation of the probability density function per arm,<br>(averaged over all simulations)', '', '',\n",
    "            arm_estimates_df, list(range(bandits.num_of_bandits)), \n",
    "            lines=True, fill=True, marker_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TODO:\n",
    "\n",
    "+ optimize the simulation functions by using numpy directly or otherwise\n",
    "+ normalize all beta distributions into a probability distribution (trivial)\n",
    "+ fancy: make a dash page/app that chooses distibutions more dynamically from the simulations cube"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "66px",
    "width": "194px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
